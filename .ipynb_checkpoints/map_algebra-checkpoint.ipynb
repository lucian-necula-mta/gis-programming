{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e7a663",
   "metadata": {},
   "source": [
    "### Local Analyses\n",
    "They work on two or more arrays that are the same size, and an algebraic equation\n",
    "is applied to each set of pixel locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2807ff",
   "metadata": {},
   "source": [
    "#### Compute NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4750d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e363ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Personale\\atm\\reps\\gis-programming\\osgeopy-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dcdcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_raster(in_ds, fn, data, data_type, nodata=None):\n",
    "    \"\"\"Create a one-band GeoTIFF.\n",
    "\n",
    "    in_ds     - datasource to copy projection and geotransform from\n",
    "    fn        - path to the file to create\n",
    "    data      - NumPy array containing data to write\n",
    "    data_type - output data type\n",
    "    nodata    - optional NoData value\n",
    "    \"\"\"\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    out_ds = driver.Create(\n",
    "        fn, in_ds.RasterXSize, in_ds.RasterYSize, 1, data_type)\n",
    "    out_ds.SetProjection(in_ds.GetProjection())\n",
    "    out_ds.SetGeoTransform(in_ds.GetGeoTransform())\n",
    "    out_band = out_ds.GetRasterBand(1)\n",
    "    if nodata is not None:\n",
    "        out_band.SetNoDataValue(nodata)\n",
    "    out_band.WriteArray(data)\n",
    "    out_band.FlushCache()\n",
    "    out_band.ComputeStatistics(False)\n",
    "    return out_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd359bd",
   "metadata": {},
   "source": [
    "**Note**: This dataset is from the National Agriculture Imagery Program (NAIP), part of the United States Department of Agriculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11aa52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(data_dir, 'Massachusetts'))\n",
    "in_fn = 'm_4207162_ne_19_1_20140718_20140923_clip.tif'\n",
    "out_fn = 'ndvi.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93738adb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = gdal.Open(in_fn)\n",
    "\n",
    "# The first band is red light, and the fourth is near-infrared, which is why you read these two bands in at the beginning\n",
    "red = ds.GetRasterBand(1).ReadAsArray().astype(np.float)\n",
    "nir = ds.GetRasterBand(4).ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9e5a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mask out the red array in all locations where the sum of the two arrays is 0.\n",
    "red = np.ma.masked_where(nir + red == 0, red)\n",
    "ndvi = (nir - red) / (nir + red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b6081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fill the empty cells\n",
    "ndvi = ndvi.filled(-99)\n",
    "\n",
    "# Set NoData to the fill value when creating the new raster.\n",
    "out_ds = pb.make_raster(ds, out_fn, ndvi, gdal.GDT_Float32, -99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d503e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overviews = compute_overview_levels(out_ds.GetRasterBand(1))\n",
    "out_ds.BuildOverviews('average', overviews)\n",
    "del ds, out_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d2ed9a",
   "metadata": {},
   "source": [
    "### Focal Analyses\n",
    " * Focal analyses use the pixels that surround the target pixel in order to calculate a value\n",
    " * For a given cell in the output, the value is calculated based on the corresponding cell and its neighbors in the input dataset\n",
    " * Once the value for the target pixel is calculated, the window moves to the next pixel.\n",
    " * Focal analyses can also be used for anything else that requires input from surrounding pixels, such as computing slope and aspect for an elevation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecc8f2",
   "metadata": {},
   "source": [
    "<img src=\"images/moving_window_analysis.png\" width =440 height = 150/>\n",
    "             \n",
    "                     moving window that calculates the average value of the nine surrounding pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2b397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "indata  = np.array([\n",
    "    [3, 5, 6, 4, 4, 3],\n",
    "    [4, 5, 8, 9, 6, 5],\n",
    "    [2, 2, 5, 7, 6, 4],\n",
    "    [5, 7, 9, 8, 9, 7],\n",
    "    [4, 6, 5, 7, 7, 5],\n",
    "    [3, 2, 5, 3, 4, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7541d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata =  np.zeros((6, 6))\n",
    "\n",
    "# Average of the nine surrounding pixels\n",
    "outdata[2,2] = (indata[1,1] + indata[1,2] + indata[1,3] +\n",
    "                indata[2,1] + indata[2,2] + indata[2,3] +\n",
    "                indata[3,1] + indata[3,2] + indata[3,3]) / 9\n",
    "print(outdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9dbddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shorter way to write the same thing\n",
    "\n",
    "outdata[2,2] = np.mean(indata[1:4, 1:4])\n",
    "print(outdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9015a53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT try this on a real image because it's way too slow.\n",
    "rows, cols = indata.shape\n",
    "outdata = np.zeros(indata.shape, np.float32)\n",
    "for i in range(1, rows-1):\n",
    "    for j in range(1, cols-1):\n",
    "        outdata[i,j] = np.mean(indata[i-1:i+2, j-1:j+2])\n",
    "print(outdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc150de4",
   "metadata": {},
   "source": [
    "**Note**: If the slices are all stacked into a three-dimensional array, then you can use the mean function, which would definitely be simpler. The `dstack` function will stack the slices on top of each other, which is what you need. But you still need to get all of the slices so you can pass them to `dstack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12549b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check out some slices\n",
    "slices = []\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        slices.append(indata[i:rows-2+i, j:cols-2+j])\n",
    "print(slices)\n",
    "\n",
    "# This is the upper left slice.\n",
    "print(slices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e5438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stack the slices in the third dimension and compute the mean.\n",
    "stacked = np.dstack(slices)\n",
    "outdata = np.zeros(indata.shape, np.float32)\n",
    "outdata[1:-1, 1:-1] = np.mean(stacked, 2)\n",
    "print(outdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get slices of any size from an array.\n",
    "def make_slices(data, win_size):\n",
    "    \"\"\"Return a list of slices given a window size.\n",
    "\n",
    "    data     - two-dimensional array to get slices from\n",
    "    win_size - tuple of (rows, columns) for the moving window\n",
    "    \"\"\"\n",
    "    # Calculate the slice size\n",
    "    rows = data.shape[0] - win_size[0] + 1\n",
    "    cols = data.shape[1] - win_size[1] + 1\n",
    "    slices = []\n",
    "\n",
    "    # Loop through the rows and columns in the provided window size and\n",
    "    # create each slice.\n",
    "    for i in range(win_size[0]):\n",
    "        for j in range(win_size[1]):\n",
    "            slices.append(data[i:rows+i, j:cols+j])\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to smooth an elevation dataset.\n",
    "in_fn = os.path.join(data_dir, 'Nepal', 'everest.tif')\n",
    "out_fn = os.path.join(data_dir, 'Nepal','everest_smoothed_edges.tif')\n",
    "\n",
    "in_ds = gdal.Open(in_fn)\n",
    "in_band = in_ds.GetRasterBand(1)\n",
    "in_data = in_band.ReadAsArray()\n",
    "\n",
    "# Stack the slices\n",
    "slices = make_slices(in_data, (3, 3))\n",
    "stacked_data = np.ma.dstack(slices)\n",
    "\n",
    "rows, cols = in_band.YSize, in_band.XSize\n",
    "\n",
    "# Initialize an output array to the NoData value (-99)\n",
    "out_data = np.ones((rows, cols), np.int32) * -99\n",
    "\n",
    "# Put the result into the middle of the output, leaving the\n",
    "# outside rows and columns alone, so they still have -99.\n",
    "out_data[1:-1, 1:-1] = np.mean(stacked_data, 2)\n",
    "\n",
    "make_raster(in_ds, out_fn, out_data, gdal.GDT_Int32, -99)\n",
    "del in_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d438d",
   "metadata": {},
   "source": [
    "Nothing is stopping you from applying much more complicated functions to the cells that make up the moving window. In fact, this is exactly what you’d want to do for many analyses.\n",
    " * One example is computing slope from an elevation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4786319c",
   "metadata": {},
   "source": [
    "<img src=\"images/slope_algorithm.png\" width =440 height = 150/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3ae2f",
   "metadata": {},
   "source": [
    "The next listing shows code for calculating the slope of the Mt. Everest DEM using these equations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9da71",
   "metadata": {},
   "source": [
    "**Note**: for this algorithm to work properly, the elevation units must be the same as the horizontal ones. For example, if your dataset uses a UTM projection, then the coordinates are expressed in meters, so the elevation values must also be meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute slope from DEM\n",
    "\n",
    "in_fn = os.path.join(data_dir, 'Nepal', 'everest_utm.tif')\n",
    "out_fn = os.path.join(data_dir,'Nepal', 'everest_slope.tif')\n",
    "\n",
    "in_ds = gdal.Open(in_fn)\n",
    "cell_width = in_ds.GetGeoTransform()[1]\n",
    "cell_height = in_ds.GetGeoTransform()[5]\n",
    "band = in_ds.GetRasterBand(1)\n",
    "in_data = band.ReadAsArray().astype(np.float)\n",
    "\n",
    "# Initialize output array with -99\n",
    "slices = os.pymake_slices(in_data, (3, 3))\n",
    "\n",
    "rise = ((slices[6] + (2 * slices[7]) + slices[8]) - (slices[0] + (2 * slices[1]) + slices[2])) / (8 * cell_height)\n",
    "run = ((slices[2] + (2 * slices[5]) + slices[8]) - (slices[0] + (2 * slices[3]) + slices[6])) / (8 * cell_width)\n",
    "\n",
    "# Output edges don’t get slope data\n",
    "dist = np.sqrt(np.square(rise) + np.square(run))\n",
    "out_data[1:-1, 1:-1] = np.arctan(dist) * 180 / np.pi\n",
    "\n",
    "make_raster(in_ds, out_fn, out_data, gdal.GDT_Float32, -99)\n",
    "del in_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dfff2f",
   "metadata": {},
   "source": [
    "#### Using SciPy for Focal Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2587912",
   "metadata": {},
   "source": [
    "SciPy is a versatile Python module designed for scientific data analysis, and it uses NumPy arrays to store large amounts of data\n",
    " * It has submodules for interpolation, Fourier transforms, linear algebra, statistics, signal processing, and image processing, among others.\n",
    " * The multidimensional image processing submodule contains filtering functions that can be used to perform the same operations you did with NumPy.\n",
    "**Note**: One advantage to using SciPy is that it will handle the edge problems for you by filling in extra cells around the edges so that the calculations can be performed on all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing filter using SciPy\n",
    "import scipy.ndimage\n",
    "\n",
    "in_fn = os.path.join(data_dir, 'Nepal', 'everest.tif')\n",
    "out_fn = os.path.join(data_dir, 'Nepal', 'everest_smoothed.tif')\n",
    "in_ds = gdal.Open(in_fn)\n",
    "in_data = in_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "# Run the filter\n",
    "out_data = scipy.ndimage.filters.uniform_filter(in_data, size=3, mode='nearest')\n",
    "make_raster(in_ds, out_fn, out_data, gdal.GDT_Int32)\n",
    "del in_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate slope using SciPy\n",
    "in_fn = os.path.join(data_dir, 'Nepal', 'everest_utm.tif')\n",
    "out_fn = os.path.join(data_dir, 'Nepal', 'everest_slope_scipy2.tif')\n",
    "\n",
    "def slope(data, cell_width, cell_height):\n",
    "    \"\"\"Calculates slope using a 3x3 window.\n",
    "    data - 1D array containing the 9 pixel values, startingin the upper left and going left to right and down\n",
    "    cell_width - pixel width in the same units as the data\n",
    "    cell_height - pixel height in the same units as the data\n",
    "    \"\"\"\n",
    "    rise = ((data[6] + (2 * data[7]) + data[8]) - (data[0] + (2 * data[1]) + data[2])) / (8 * cell_height)\n",
    "    run = ((data[2] + (2 * data[5]) + data[8]) - (data[0] + (2 * data[3]) + data[6])) / (8 * cell_width)\n",
    "\n",
    "    dist = np.sqrt(np.square(rise) + np.square(run))\n",
    "    return np.arctan(dist) * 180 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ds = gdal.Open(in_fn)\n",
    "in_band = in_ds.GetRasterBand(1)\n",
    "in_data = in_band.ReadAsArray().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_width = in_ds.GetGeoTransform()[1]\n",
    "cell_height = in_ds.GetGeoTransform()[5]\n",
    "\n",
    "# Run the filter\n",
    "out_data = scipy.ndimage.filters.generic_filter( \n",
    "                                in_data, slope, size=3, mode='nearest', extra_arguments=(cell_width, cell_height)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_raster(in_ds, out_fn, out_data, gdal.GDT_Float32)\n",
    "del in_ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
